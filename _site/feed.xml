<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-05-13T04:55:21-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">JeongUk Jang</title><subtitle>Github Pages template for academic personal websites, forked from mmistakes/minimal-mistakes</subtitle><author><name>{&quot;name&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;employer&quot;=&gt;nil, &quot;pubmed&quot;=&gt;nil, &quot;googlescholar&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;blanik00@gmail.com&quot;, &quot;researchgate&quot;=&gt;nil, &quot;uri&quot;=&gt;nil, &quot;bitbucket&quot;=&gt;nil, &quot;codepen&quot;=&gt;nil, &quot;dribbble&quot;=&gt;nil, &quot;flickr&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;foursquare&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;google_plus&quot;=&gt;nil, &quot;keybase&quot;=&gt;nil, &quot;instagram&quot;=&gt;nil, &quot;impactstory&quot;=&gt;nil, &quot;lastfm&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;orcid&quot;=&gt;nil, &quot;pinterest&quot;=&gt;nil, &quot;soundcloud&quot;=&gt;nil, &quot;stackoverflow&quot;=&gt;nil, &quot;steam&quot;=&gt;nil, &quot;tumblr&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;vine&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;xing&quot;=&gt;nil, &quot;youtube&quot;=&gt;nil, &quot;wikipedia&quot;=&gt;nil}</name><email>blanik00@gmail.com</email></author><entry><title type="html">YOLO, SSD, YOLO 9000</title><link href="http://localhost:4000/posts/2020/05/10/yolo" rel="alternate" type="text/html" title="YOLO, SSD, YOLO 9000" /><published>2020-05-11T00:00:00-07:00</published><updated>2020-05-11T00:00:00-07:00</updated><id>http://localhost:4000/posts/2020/05/10/yolo</id><content type="html" xml:base="http://localhost:4000/posts/2020/05/10/yolo">&lt;h2 id=&quot;yolo&quot;&gt;YOLO&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;You only look once!&lt;/li&gt;
  &lt;li&gt;성능 자체는 Faster R-CNN과 비슷하나, 속도가 훨씬 빠름&lt;/li&gt;
  &lt;li&gt;기존의 방법에서는 bounding box를 만들어서 그것을 Neural Network에 넣어 분류를 하는 방법을 사용했다면 YOLO에서는 bounding box를 찾는 것과 classification을 동시에 수행한다. (detection 문제를 regression 문제로 바꿈)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;flow&quot;&gt;Flow&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;이미지를 입력받으면 $S\times S$로 줄인다.(Max Pooling을 통해서 줄임, 여기서 $S$=7) 각 칸을 그리드라고 부른다.&lt;/li&gt;
  &lt;li&gt;각 그리드마다  class probability를 C개씩, bounding box를 B개씩 부여한다. 각 bounding box는 [x, y, w, h, conf]로 이루어져 있다. 마지막에 있는 conf(confidence)는 이 bounding box가 쓸모있는 것인지 아닌지를 나타낸다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;만약 S=7, B=2, C=20이라면 마지막 layer는 $7\times 7\times 30$이다.($30=20+2\times 5$)&lt;/p&gt;

&lt;h3 id=&quot;yolo의-한계&quot;&gt;YOLO의 한계&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;각 그리드가 B개 만의 bounding box만을 만드므로 조그마한 물체들이 뭉쳐 있을 때는 좋은 성능을 발휘하지 못한다.&lt;/li&gt;
  &lt;li&gt;bounding box의 정보가 정확하지 않을 수 있다.&lt;/li&gt;
  &lt;li&gt;Loss Function이 작은 box와 큰 box를 동일하게 다뤄 에러를 측정하므로 점수를 메길 때 불리하다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;ssd&quot;&gt;SSD&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Single Shot MultiBox Detector&lt;/li&gt;
  &lt;li&gt;YOLO의 컨셉(Single Shot)과 Faster R-CNN의 Region Proposal(MultiBox)을 합친 것&lt;/li&gt;
  &lt;li&gt;Predicting category scores from each cell of multiple convolutional feature maps.&lt;/li&gt;
  &lt;li&gt;Predicting Box offsets for a fixed set of default boxes from each cell of multiple convolutional feature maps.&lt;/li&gt;
  &lt;li&gt;즉, 각 feature map의 셀 마다 k개의 default box(anchor box)를 가지며, 각 box는 c개의 class score와 4개의 offset을 가지고 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;yolo-9000&quot;&gt;YOLO 9000&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;SSD보다 좋은 성능을 내기 위해 이것저것 많은 시도를 한 논문. 실용적인 내용이 많다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;yolo가-잘-안됐던-이유&quot;&gt;YOLO가 잘 안됐던 이유&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Localization Errors&lt;/li&gt;
  &lt;li&gt;Low recall compared region proposal based method
box를 적게 뽑았으니 recall 성능이 낮았다는 말임.
&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/81780462-85443f80-9531-11ea-9085-b056bb24514d.jpg&quot; alt=&quot;1&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;개선-방법faster&quot;&gt;개선 방법(Faster)&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Batch Normalization
2% 성능 개선(웬만하면 Batch Normalization 쓰는 것이 좋음)&lt;/li&gt;
  &lt;li&gt;High Resolution
original YOLO는 $224\times 224$를 썼는데, 여기서는 $448\times 448$을 썼다.&lt;/li&gt;
  &lt;li&gt;Anchor Boxes
Region Proposal Network에서 사용된 anchor box와 비슷한 것을 사용
anchor box마다 class와 objectiveness를 예측&lt;/li&gt;
  &lt;li&gt;Dimension Cluster
기존에는 anchor box의 pre-defined 크기를 정할 때 실제 데이터셋의 box 크기르 고려하지 않고 사람이 임의로 정했다. YOLO 9000에서는 실제 데이터셋에서 bounding box를 클러스터링해서 거기에 많이 쓰이는 bounding box 크기를 사용&lt;/li&gt;
  &lt;li&gt;Location Prediction
YOLO 9000은 box offset과 scaling을 예측한다. 즉, 사이즈를 몇 배 키울지 혹은 줄일지를 예측&lt;/li&gt;
  &lt;li&gt;Fine-grained Features&lt;/li&gt;
  &lt;li&gt;Multi-scale Training&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;개선-방법stronger&quot;&gt;개선 방법(Stronger)&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Hierarchical classification
YOLO 9000은 9000개의 클래스를 구분할 수 있다는 말이다. 9000개 중 하나를 찾는 것은 매우 힘든 일이다. 그래서 여기서는 Hierarchical classification을 적용한다. 예를 들어, 요커셔 테리어를 생각해보면 “physical object” - “animal” - “mammal” - … - “hunting dog” - “terrior” - Yorkshire terriror”라는 식으로 parent에 해당하는 라벨도 생각해낼 수 있다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/81780457-837a7c00-9531-11ea-8b3c-177b763d78ae.PNG&quot; alt=&quot;2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림처럼  위계마다 하나의 클래스를 선택한다. 결과적으로는 한 이미지를 입력하면 여러 개의 클래스를 가지는 결과가 나온다.&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;employer&quot;=&gt;nil, &quot;pubmed&quot;=&gt;nil, &quot;googlescholar&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;blanik00@gmail.com&quot;, &quot;researchgate&quot;=&gt;nil, &quot;uri&quot;=&gt;nil, &quot;bitbucket&quot;=&gt;nil, &quot;codepen&quot;=&gt;nil, &quot;dribbble&quot;=&gt;nil, &quot;flickr&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;foursquare&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;google_plus&quot;=&gt;nil, &quot;keybase&quot;=&gt;nil, &quot;instagram&quot;=&gt;nil, &quot;impactstory&quot;=&gt;nil, &quot;lastfm&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;orcid&quot;=&gt;nil, &quot;pinterest&quot;=&gt;nil, &quot;soundcloud&quot;=&gt;nil, &quot;stackoverflow&quot;=&gt;nil, &quot;steam&quot;=&gt;nil, &quot;tumblr&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;vine&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;xing&quot;=&gt;nil, &quot;youtube&quot;=&gt;nil, &quot;wikipedia&quot;=&gt;nil}</name><email>blanik00@gmail.com</email></author><category term="[&quot;posts&quot;]" /><summary type="html">YOLO You only look once! 성능 자체는 Faster R-CNN과 비슷하나, 속도가 훨씬 빠름 기존의 방법에서는 bounding box를 만들어서 그것을 Neural Network에 넣어 분류를 하는 방법을 사용했다면 YOLO에서는 bounding box를 찾는 것과 classification을 동시에 수행한다. (detection 문제를 regression 문제로 바꿈)</summary></entry><entry><title type="html">R-CNN, SPP, Fast R-CNN, Faster R-CNN</title><link href="http://localhost:4000/posts/2020/05/10/r-cnn" rel="alternate" type="text/html" title="R-CNN, SPP, Fast R-CNN, Faster R-CNN" /><published>2020-05-10T00:00:00-07:00</published><updated>2020-05-10T00:00:00-07:00</updated><id>http://localhost:4000/posts/2020/05/10/r-cnn</id><content type="html" xml:base="http://localhost:4000/posts/2020/05/10/r-cnn">&lt;h2 id=&quot;r-cnn&quot;&gt;R-CNN&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/81771298-92573380-951d-11ea-8aea-25f440c43aec.PNG&quot; alt=&quot;1&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;최초로 딥러닝을 활용해 detection 문제에 접근&lt;/li&gt;
  &lt;li&gt;매우 간단&lt;/li&gt;
  &lt;li&gt;이미지 안에서 여러 개의 bounding box를 뽑아냄.(region proposal) 이 부분은 딥러닝을 사용하지 않았으며, 속도가 느리기 때문에 bottle neck이 된다. selective search 방법을 사용한다.&lt;/li&gt;
  &lt;li&gt;모든 bounding box를 같은 사이즈로 resize하고, resize된 box를 CNN에 넣어 feature를 추출한다. (모든 box에 대해 CNN을 수행하므로 속도가 느림)&lt;/li&gt;
  &lt;li&gt;추출된 feature를 SVM으로 분류한다.&lt;/li&gt;
  &lt;li&gt;분류 카테고리가 $n$개라면 실제로는 “background”까지 포함해 $n+1$개가 되어야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;spp&quot;&gt;SPP&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/81771299-93886080-951d-11ea-81d7-9e532edc17ed.PNG&quot; alt=&quot;2&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;RCNN은 한 이미지의 region proposals의 수만큼 CNN이 돌아야 했다. 이 부분 때문에 bottle neck이 생겼는데, SPP는 한 번만 돌면 되도록 개선시켰다.&lt;/li&gt;
  &lt;li&gt;SPP는 convolution 연산을 한 후에 나오는 convolutional feature map 위에서 원하는 정보를 찾는다. convolutional feature map에서 뽑히는 박스의 위치는 이미지에서 뽑힌 bounding box의 위치에서 뽑는다.(이 때도 딥러닝을 사용하지는 않는다) box를 뽑았다면 Spatial Pyramid Pooling을 사용한다. Spatial Pyramid Pooling의 목적은 fixed-length representation을 찾는 것이다.&lt;/li&gt;
  &lt;li&gt;Spatial Pyramid Pooling이란 무엇일까?
만약 우리가 뽑은 convolution feature map에서 뽑은 박스의 사이즈가 $2\times 4$라고 하자.&lt;br /&gt;
우리가 구하고자 하는 fixed-length가 $1\times 1$이라고 한다면 $2\times 4$의 값들을 평균내어 사용한다.&lt;br /&gt;
또한 우리가 구하고자 하는 fixed-length가 $2\times 2$라고 한다면 $2\times 4$를 네 부분으로 나누어 각각을 평균내어 사용한다. 즉, Pooling을 통해 같은 사이즈로 바꾸는 작업이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;fast-r-cnn&quot;&gt;Fast R-CNN&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/81771301-9420f700-951d-11ea-988e-1f6f110c6c02.PNG&quot; alt=&quot;3&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Fast R-CNN과 SPP는 구조가 거의 같다.&lt;/li&gt;
  &lt;li&gt;굳이 차이점이 있다면 fixed-length representation을 찾는 방식에 차이가 있다. SPP는 Spatial Pyramid Pooling을 사용하였고, Fast R-CNN은 ROI Pooling을 통해 찾는다. 사실 이 둘도 비슷하긴 하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;flow&quot;&gt;Flow&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;입력 이미지를 받고, 입력 이미지로부터 bounding box를 뽑는다.(딥러닝을 사용하지 않는다.)&lt;/li&gt;
  &lt;li&gt;CNN을 통해 convolutional feature map을 생성한다.&lt;/li&gt;
  &lt;li&gt;ROI Pooling을 통해 각 bounding box의 fixed-length feature vector를 만든다.&lt;/li&gt;
  &lt;li&gt;결과는 두 가지가 되는데, 하나는 “background”를 고려한 (k+1) classification이고, 다른 하나는 bounding box regression이다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;roi-pooling&quot;&gt;ROI Pooling&lt;/h3&gt;
&lt;p&gt;입력을 미리 정해둔 사이즈로 쪼갠 후, 해당 하는 부분을 평균내서 벡터로 만든다. 예를 들어, $3\times 3$으로 쪼개는 것으로 정해뒀다면 입력을 $3\times 3$으로 쪼개고, 각각을 평균낸 후 이어붙여 길이가 9인 벡터로 만든다.&lt;/p&gt;

&lt;h2 id=&quot;faster-r-cnn&quot;&gt;Faster R-CNN&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/81771304-94b98d80-951d-11ea-9505-6f5ac079ca4d.PNG&quot; alt=&quot;4&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;지금까지 배운 것은 나이브한 방법에 딥러닝을 바로 적용한 detection 방법론이었다. 하지만 여기부터는 딥러닝을 활용한 region proposal이 시작된다. (기존에는 이 부분이 bottleneck이었음)&lt;/li&gt;
  &lt;li&gt;Faster R-CNN = Region Proposal Network + Fast R-CNN&lt;/li&gt;
  &lt;li&gt;어떠한 이미지의 사이즈와 스케일이 다를 때 고려할 수 있는 방법은 세 가지가 있다. 첫 번째 방법은 Pyramids of images이며, Spatial Pyramid Pooling이 여기에 해당된다. 이미지 자체의 사이즈를 줄여서 줄어든 multiple scaled image를 한 번에 고려하는 것이다. 두 번째 방법은 Pyramids of filters이며, 이 방법은 필터의 사이즈를 바꾸는 것이다. 세 번째 방법이 &lt;strong&gt;Pyramids of anchors&lt;/strong&gt;이다. Anchor는 미리 정해져있는 bounding box의 크기를 의미한다. 미리 bounding box의 크기가 어느정도 될 것인지를 생각을 해두고, 이 box를 얼만큼 바꿔야지 target box가 되는지에 해당하는 offset을 학습한다.&lt;/li&gt;
  &lt;li&gt;Region Proposal Network는 이미지나 convolutional feature map을 입력으로 받는다. 각 픽셀마다 Anchor를 정의한다. 각 점을 중앙으로 하는 k개의 Anchor box를 만든다. 각 Anchor box마다 2개의 점수를 할당하는데(2k scores) 앞의 것이 크면 positive(쓸만한 Anchor box), 뒤의 것이 크면 negative(쓸모없는 Anchor box)이다. 또한 4k coordinates는 각 Anchor boxes를 어떻게 움직여야 target box에 가까워질 것인지에 대한 숫자가 들어있다.&lt;/li&gt;
  &lt;li&gt;즉, Region Proposal Network는 총 $k\times (4+2)$ 사이즈의 벡터를 출력한다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;employer&quot;=&gt;nil, &quot;pubmed&quot;=&gt;nil, &quot;googlescholar&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;blanik00@gmail.com&quot;, &quot;researchgate&quot;=&gt;nil, &quot;uri&quot;=&gt;nil, &quot;bitbucket&quot;=&gt;nil, &quot;codepen&quot;=&gt;nil, &quot;dribbble&quot;=&gt;nil, &quot;flickr&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;foursquare&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;google_plus&quot;=&gt;nil, &quot;keybase&quot;=&gt;nil, &quot;instagram&quot;=&gt;nil, &quot;impactstory&quot;=&gt;nil, &quot;lastfm&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;orcid&quot;=&gt;nil, &quot;pinterest&quot;=&gt;nil, &quot;soundcloud&quot;=&gt;nil, &quot;stackoverflow&quot;=&gt;nil, &quot;steam&quot;=&gt;nil, &quot;tumblr&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;vine&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;xing&quot;=&gt;nil, &quot;youtube&quot;=&gt;nil, &quot;wikipedia&quot;=&gt;nil}</name><email>blanik00@gmail.com</email></author><category term="[&quot;posts&quot;]" /><summary type="html">R-CNN 최초로 딥러닝을 활용해 detection 문제에 접근 매우 간단 이미지 안에서 여러 개의 bounding box를 뽑아냄.(region proposal) 이 부분은 딥러닝을 사용하지 않았으며, 속도가 느리기 때문에 bottle neck이 된다. selective search 방법을 사용한다. 모든 bounding box를 같은 사이즈로 resize하고, resize된 box를 CNN에 넣어 feature를 추출한다. (모든 box에 대해 CNN을 수행하므로 속도가 느림) 추출된 feature를 SVM으로 분류한다. 분류 카테고리가 $n$개라면 실제로는 “background”까지 포함해 $n+1$개가 되어야 한다.</summary></entry><entry><title type="html">CNN</title><link href="http://localhost:4000/posts/2020/05/09/cnn" rel="alternate" type="text/html" title="CNN" /><published>2020-05-09T00:00:00-07:00</published><updated>2020-05-09T00:00:00-07:00</updated><id>http://localhost:4000/posts/2020/05/09/CNN</id><content type="html" xml:base="http://localhost:4000/posts/2020/05/09/cnn">&lt;h2 id=&quot;cnn이란&quot;&gt;CNN이란?&lt;/h2&gt;
&lt;p&gt;CNN은 아래 세 가지 요소로 이루어져 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Convolution : Input Image에 Convolution 연산을 하면 “Convolutional Feature Map”이 나온다.&lt;/li&gt;
  &lt;li&gt;Subsampling : sampling을 통해 image 혹은 feature map의 크기(spatial한 정보)가 줄어듦.&lt;/li&gt;
  &lt;li&gt;Full Connection(Dense)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Convolution과 Subsampling은 &lt;strong&gt;특성 추출(feature extraction)&lt;/strong&gt;을 수행한다. 즉, CNN은 feature들의 조합으로 물체를 구분한다.&lt;/p&gt;

&lt;p&gt;또한 Full Connection은 feature들을 기반으로 분류를 수행한다.&lt;/p&gt;

&lt;p&gt;즉, CNN은 이미지로부터 특징을 추출해내고, 이를 기반으로 분류를 하는 모델이다.&lt;/p&gt;

&lt;h2 id=&quot;왜-cnn이-잘-될까&quot;&gt;왜 CNN이 잘 될까?&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Local Invariance
동일한 사이즈의 filter가 이미지의 모든 부분을 돌아다니기 때문에 찾고자 하는 이미지가 어디에 있는지는 중요하지 않다.&lt;/li&gt;
  &lt;li&gt;Compositionality
CNN을 여러 층 쌓으면 계층 구조가 생겨 성능이 좋다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;convolution이란&quot;&gt;Convolution이란&lt;/h2&gt;
&lt;p&gt;이미지의 특정 부분과 filter가 얼마나 유사한지 연산하는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/81528300-572af800-9397-11ea-9833-d7abea9d8664.png&quot; alt=&quot;1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림에서 Image의 진한 파란 부분과 filter의 convolution 연산을 수행한다면 두 행렬을 element-wise product하고 sum하면 된다. (=51)&lt;/p&gt;

&lt;p&gt;해당 부분에 대한 convolution을 완료했다면, 다음 칸으로 옮겨 동일한 연산을 수행한다.&lt;/p&gt;

&lt;h2 id=&quot;zero-padding&quot;&gt;Zero-Padding&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/81528296-54c89e00-9397-11ea-9864-7c430aa6c784.gif&quot; alt=&quot;2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Convolution을 해야 하는데, 이를 위해서는 원본 이미지의 사이즈를 좀 더 크게 만들어야 할 때 zero-padding을 한다. 위 그림에서 실선 부분이 zero-padding한 곳이다.&lt;/p&gt;

&lt;h2 id=&quot;stride&quot;&gt;Stride&lt;/h2&gt;
&lt;p&gt;Convolution 연산을 마치고 몇 칸을 뛰는지를 결정하는 것이 Stride이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/81528298-56926180-9397-11ea-9723-a2f49c6c2d26.png&quot; alt=&quot;3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림에서 왼쪽은 stride=1이고, 오른쪽은 stride=2이다.&lt;/p&gt;

&lt;p&gt;stride의 수와 filter의 Width, Height가 같다면 Overlapping없이 feature map을 생성할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;input-image&quot;&gt;Input Image&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;[batch, in_height, in_width, in_channels]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;batch : batch size
in_channels : RGB인 경우 3, Grey인 경우 1&lt;/p&gt;

&lt;h2 id=&quot;filter&quot;&gt;Filter&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;[filter_height, filter_width, in_channels, out_channels]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;input_ image의 in_channels와 filter의 in_channels는 항상 같아야 한다.
out_channels는 필터의 개수&lt;/p&gt;

&lt;h2 id=&quot;파라미터의-수&quot;&gt;파라미터의 수&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;모델 보면 파리미터의 수를 셀 줄 알아야 한다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$4\times 4\times 3$ 이미지를 $3\times 3\times 3$ filter로 convolution해서 $4\times 4\times 7$인 feature map이 나왔다고 하자. 이 경우 filter_height=3, filter_width=3, in_channels=3, out_channels=7이므로, 파라미터의 수는 $3\times 3\times 3 \times 7=189$이다.&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;employer&quot;=&gt;nil, &quot;pubmed&quot;=&gt;nil, &quot;googlescholar&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;blanik00@gmail.com&quot;, &quot;researchgate&quot;=&gt;nil, &quot;uri&quot;=&gt;nil, &quot;bitbucket&quot;=&gt;nil, &quot;codepen&quot;=&gt;nil, &quot;dribbble&quot;=&gt;nil, &quot;flickr&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;foursquare&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;google_plus&quot;=&gt;nil, &quot;keybase&quot;=&gt;nil, &quot;instagram&quot;=&gt;nil, &quot;impactstory&quot;=&gt;nil, &quot;lastfm&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;orcid&quot;=&gt;nil, &quot;pinterest&quot;=&gt;nil, &quot;soundcloud&quot;=&gt;nil, &quot;stackoverflow&quot;=&gt;nil, &quot;steam&quot;=&gt;nil, &quot;tumblr&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;vine&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;xing&quot;=&gt;nil, &quot;youtube&quot;=&gt;nil, &quot;wikipedia&quot;=&gt;nil}</name><email>blanik00@gmail.com</email></author><category term="[&quot;posts&quot;]" /><summary type="html">CNN이란? CNN은 아래 세 가지 요소로 이루어져 있다.</summary></entry><entry><title type="html">최대우도추정(MLE, Maximum Likelihood Estimation)</title><link href="http://localhost:4000/posts/2020/05/03/maximum_likelihood_estimation" rel="alternate" type="text/html" title="최대우도추정(MLE, Maximum Likelihood Estimation)" /><published>2020-05-03T00:00:00-07:00</published><updated>2020-05-03T00:00:00-07:00</updated><id>http://localhost:4000/posts/2020/05/03/maximum_likelihood_estimation</id><content type="html" xml:base="http://localhost:4000/posts/2020/05/03/maximum_likelihood_estimation">&lt;iframe src=&quot;https://www.youtube.com/embed/XepXtl9YKwc&quot;&gt; &lt;/iframe&gt;

&lt;p&gt;최대우도추정 : 데이터를 가장 잘 설명하는 모델의 모수($\theta$)를 찾는 것&lt;/p&gt;

&lt;p&gt;관측된 데이터 $X_1=x_1$, $X_2=x_2$, …, $X_n=x_n$이 있다고 할 때 $\theta$의 가능도는 다음과 같다.&lt;/p&gt;

&lt;p&gt;$L(\theta)=P(x_1, x_2, …, x_n|\theta)$&lt;/p&gt;

&lt;p&gt;(참고로 여기서 나오는 $P(x_1, x_2, …, x_n|\theta)$에서 $|$는 조건부 확률을 나타내는 기호가 아니다. $|$ 뒤에 있는 기호들이 모델의 모수라는 것을 강조하기 위해 사용되는 기호에 불과하다. $P(x_1, x_2, …, x_n;\theta)$으로 표현하기도 한다.)&lt;/p&gt;

&lt;p&gt;이 때 확률변수가 iid(independent and identically distributed)라면 가능도는 다음과 같이 표현할 수도 있다.&lt;/p&gt;

&lt;p&gt;$L(\theta)=\prod_{i=1}^{n}P(x_i|\theta)$&lt;/p&gt;

&lt;p&gt;가능도를 최대로 만드는 $\theta_{MLE}$는 다음과 같다.&lt;/p&gt;

&lt;p&gt;$\theta_{MLE}=argmax_{\theta}\prod_{i=1}^nP(x_i|\theta)$&lt;/p&gt;

&lt;p&gt;이 때 확률값은 1보다 작기 때문에 계속 곱하면 그 값이 지나치게 작아져 언더플로우(underflow) 문제가 발생하므로 로그를 취한다. 이 때 로그를 취하더라도 가능도를 최대로 만드는 $\theta$가 전과 동일하다는 보장이 있어야 하는데, 로그는 단조증가(monotonically increasing)한다는 성질이 있기 때문에 로그를 취하더라도 가능도를 최대로 만드는 $\theta$는 변하지 않는다.&lt;/p&gt;

&lt;p&gt;$\theta_{MLE}=argmax_{\theta}\sum_{i=1}^nlogP(x_i|\theta)$&lt;/p&gt;

&lt;h2 id=&quot;예시&quot;&gt;예시&lt;/h2&gt;
&lt;iframe src=&quot;https://www.youtube.com/embed/Dn6b9fCIUpM&quot;&gt; &lt;/iframe&gt;

&lt;h2 id=&quot;출처&quot;&gt;출처&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=XepXtl9YKwc&quot;&gt;StatQuest: Maximum Likelihood, clearly explained!!!&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://www.youtube.com/watch?v=Dn6b9fCIUpM&quot;&gt;Maximum Likelihood For the Normal Distribution, step-by-step!&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://ratsgo.github.io/statistics/2017/09/23/MLE/&quot;&gt;최대우도추정(Maximum Likelihood Estimation)&lt;/a&gt;&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;employer&quot;=&gt;nil, &quot;pubmed&quot;=&gt;nil, &quot;googlescholar&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;blanik00@gmail.com&quot;, &quot;researchgate&quot;=&gt;nil, &quot;uri&quot;=&gt;nil, &quot;bitbucket&quot;=&gt;nil, &quot;codepen&quot;=&gt;nil, &quot;dribbble&quot;=&gt;nil, &quot;flickr&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;foursquare&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;google_plus&quot;=&gt;nil, &quot;keybase&quot;=&gt;nil, &quot;instagram&quot;=&gt;nil, &quot;impactstory&quot;=&gt;nil, &quot;lastfm&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;orcid&quot;=&gt;nil, &quot;pinterest&quot;=&gt;nil, &quot;soundcloud&quot;=&gt;nil, &quot;stackoverflow&quot;=&gt;nil, &quot;steam&quot;=&gt;nil, &quot;tumblr&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;vine&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;xing&quot;=&gt;nil, &quot;youtube&quot;=&gt;nil, &quot;wikipedia&quot;=&gt;nil}</name><email>blanik00@gmail.com</email></author><category term="[&quot;posts&quot;]" /><summary type="html"></summary></entry><entry><title type="html">확률(Probability)과 가능도(Likelihood)의 차이</title><link href="http://localhost:4000/posts/2020/05/02/probability_likelihood" rel="alternate" type="text/html" title="확률(Probability)과 가능도(Likelihood)의 차이" /><published>2020-05-02T00:00:00-07:00</published><updated>2020-05-02T00:00:00-07:00</updated><id>http://localhost:4000/posts/2020/05/02/probability_likelihood</id><content type="html" xml:base="http://localhost:4000/posts/2020/05/02/probability_likelihood">&lt;iframe src=&quot;https://www.youtube.com/embed/pYxNSUDSFH4&quot;&gt; &lt;/iframe&gt;

&lt;p&gt;확률과 가능도의 차이를 가장 직관적으로 설명한 영상이라고 생각한다. 한번 보면 감이 올 것이다.&lt;/p&gt;

&lt;p&gt;영상에서는 확률과 가능도를 다음과 같이 요약한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/80852722-b4230180-8c65-11ea-9d9f-922949fad27c.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;내-나름의-정리&quot;&gt;내 나름의 정리&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;확률 : 분포를 알고 있을 때, 전체 관측값에서 우리가 관심있는 관측값이 차지하는 비중&lt;/li&gt;
  &lt;li&gt;가능도 : 분포를 모를 때, 분포 $\theta$가 관측값을 얼마나 잘 설명하는지 수치화한 것&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;출처&quot;&gt;출처&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw&quot;&gt;StatQuest with Josh Starmer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/2641/what-is-the-difference-between-likelihood-and-probability&quot;&gt;What is the difference between “likelihood” and “probability”?
&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;employer&quot;=&gt;nil, &quot;pubmed&quot;=&gt;nil, &quot;googlescholar&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;blanik00@gmail.com&quot;, &quot;researchgate&quot;=&gt;nil, &quot;uri&quot;=&gt;nil, &quot;bitbucket&quot;=&gt;nil, &quot;codepen&quot;=&gt;nil, &quot;dribbble&quot;=&gt;nil, &quot;flickr&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;foursquare&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;google_plus&quot;=&gt;nil, &quot;keybase&quot;=&gt;nil, &quot;instagram&quot;=&gt;nil, &quot;impactstory&quot;=&gt;nil, &quot;lastfm&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;orcid&quot;=&gt;nil, &quot;pinterest&quot;=&gt;nil, &quot;soundcloud&quot;=&gt;nil, &quot;stackoverflow&quot;=&gt;nil, &quot;steam&quot;=&gt;nil, &quot;tumblr&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;vine&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;xing&quot;=&gt;nil, &quot;youtube&quot;=&gt;nil, &quot;wikipedia&quot;=&gt;nil}</name><email>blanik00@gmail.com</email></author><category term="[&quot;posts&quot;]" /><summary type="html"></summary></entry><entry><title type="html">Neural Collaborative Filtering</title><link href="http://localhost:4000/paper_review/2020/04/24/Neural_Collaborative_Filtering" rel="alternate" type="text/html" title="Neural Collaborative Filtering" /><published>2020-04-24T00:00:00-07:00</published><updated>2020-04-24T00:00:00-07:00</updated><id>http://localhost:4000/paper_review/2020/04/24/Neural_Collaborative_Filtering</id><content type="html" xml:base="http://localhost:4000/paper_review/2020/04/24/Neural_Collaborative_Filtering">&lt;h1 id=&quot;요약&quot;&gt;요약&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Implicit Feedback을 활용한 Collaborative Filtering을 다룬다.&lt;/li&gt;
  &lt;li&gt;output이 1이면 User와 Item은 연관성이 있는 것이며, 0이면 User와 Item은 연관성이 없는 것이다. 즉, binary classification 문제이다.&lt;/li&gt;
  &lt;li&gt;Collaborative Filtering에서 Matrix Factorization은 많이 쓰이는 기법이다.&lt;/li&gt;
  &lt;li&gt;기존의 Matrix Factorization은 User Latent Factor와 Item Latent Factor를 구하고, 두 Latent Factor를 내적하는 방법을 통해 Rating Matrix를 복원한다.&lt;/li&gt;
  &lt;li&gt;하지만 이 방법은 User-Item Interaction을 충분히 표현하지 못한다.&lt;/li&gt;
  &lt;li&gt;저자는 &lt;strong&gt;내적&lt;/strong&gt;이라는 지나치게 단순한 방법으로 Rating Matrix를 복원했기 때문이라고 본다.&lt;/li&gt;
  &lt;li&gt;대안으로 &lt;strong&gt;뉴럴 네트워크&lt;/strong&gt;의 사용을 권한다.&lt;/li&gt;
  &lt;li&gt;뉴럴 네트워크를 도입함으로써 Matrix Factorization이 가지는 Linearity와 뉴럴 네트워크가 가지는 Non-Linearity를 모두 가질 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;문제-제시&quot;&gt;문제 제시&lt;/h1&gt;
&lt;p&gt;기존의 Matrix Factorization은 SGD나 ALS 등의 방법을 사용해서 User-Item Interaction($M\times N$)을 User Latent Factor($M\times K$)와 Item Latent Factor($K\times N$)로 분해한다(K « M, N).&lt;/p&gt;

&lt;p&gt;그 후 두 Latent Factor를 내적해 Rating Matrix를 복원하는 방법을 통해 User가 Item을 얼마나 선호하는지 등을 예측한다.&lt;br /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/80499831-6a59c300-89a8-11ea-9e96-de5ff1654354.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;내적의 의미를 생각해보면 내적을 한다는 것은 User Latent Factor와 Item Latent Factor를 선형 결합해서 Rating Matrix를 복원한다는 것이다(Linear). 하지만 Linear한 방법은 단순한 예제에서는 잘 작동하지만, User-Item Interaction과 같이 복잡한 관계를 가지는 것을 잘 표현하지 못한다는 단점이 있다.&lt;/p&gt;

&lt;h1 id=&quot;대안-제시&quot;&gt;대안 제시&lt;/h1&gt;
&lt;p&gt;저자는 이 문제를 해결하기 위해 두 가지 방법이 있다고 말한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Latent Factor의 Dimension(K)을 늘리는 것&lt;/li&gt;
  &lt;li&gt;Non-Linear한 방법을 통해 모델 구축&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;둘 다 좋은 방법이지만 1번 방법의 경우 오버피팅이 발생한다는 문제가 있어 2번 방법을 채택했으며, Non-Linearity를 추가하기 위한 방법으로 Neural Network를 도입한 것이다.&lt;/p&gt;

&lt;h1 id=&quot;뉴럴-네트워크-도입으로-인해-달라지는-것들&quot;&gt;뉴럴 네트워크 도입으로 인해 달라지는 것들&lt;/h1&gt;

&lt;h2 id=&quot;1-embedding-layer&quot;&gt;1. Embedding Layer&lt;/h2&gt;
&lt;p&gt;Embedding Layer를 한 문장으로 표현하면 다음과 같다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Turns positive integers (indexes) into dense vectors of fixed size.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;즉, categorical한 input을 고정된 사이즈의 dense한 벡터로 바꿔주는 Layer이다. 이 논문에서는 User Latent Factor와 Item Latent Factor를 표현하는 데 사용한다.&lt;/p&gt;
&lt;h2 id=&quot;2-필요한-모델&quot;&gt;2. 필요한 모델&lt;/h2&gt;
&lt;h3 id=&quot;0-neural-collaborative-filtering-framework&quot;&gt;(0) Neural Collaborative Filtering Framework&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/80499827-69c12c80-89a8-11ea-920a-969720de8bec.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;뒤에 나오는 모델들의 뼈대가 되는 것이다. 다음과 같은 과정을 거친다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Input Layer&lt;/li&gt;
  &lt;li&gt;Embedding Layer&lt;/li&gt;
  &lt;li&gt;Neural CF Layers&lt;/li&gt;
  &lt;li&gt;Output Layer&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;1-mlpmulti-layer-perceptron&quot;&gt;(1) MLP(Multi-Layer Perceptron)&lt;/h3&gt;

&lt;p&gt;앞의 Neural Collaborative Filtering Framework을 충실히 재현한 모델이다. User Latent Factor와 Item Latent Factor를 여러 Layer를 거치게 해 결과를 낸다.(Layer의 activation function을 relu로 해 Non-Linearity를 얻는다.)&lt;/p&gt;

&lt;p&gt;수식으로 표현하면 다음과 같다.&lt;br /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/80499829-6a59c300-89a8-11ea-97fb-11ba105acc76.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;$W_x$ : weight matrix for x-th layer&lt;br /&gt;
$b_x$ : bias vector for x-th layer&lt;br /&gt;
$a_x$ : activation function for x-th layer&lt;br /&gt;
$h$ : edge weights of the output layer&lt;/p&gt;

&lt;p&gt;수식에서 볼 수 있듯이 첫 번째 layer는 User Latent Factor와 Item Latent Factor를 Concatenate한 것이다.&lt;/p&gt;

&lt;h3 id=&quot;2-gmfgeneralized-matrix-factorization&quot;&gt;(2) GMF(Generalized Matrix Factorization)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/80499823-69289600-89a8-11ea-959a-3d6377197ead.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이번에는 앞에서 본 Neural Collaborative Filtering Framework의 특별한 케이스 중 하나를 다룰 것이다.&lt;/p&gt;

&lt;p&gt;수식으로 표현하면 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/80499822-688fff80-89a8-11ea-8ca8-fa287685f3d2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;$a_{out}$ : activation function&lt;br /&gt;
$h$ : edge weights of the output layer&lt;br /&gt;
$\odot$ : element-wise product&lt;/p&gt;

&lt;p&gt;만약 activation function으로 non-linear한 함수를 사용하면 non-linear한 	모델로도 사용할 수 있다. 하지만 논문에서 저자는 GMF 모델이 Linearity를 가지게 한다(저자가 작성한 &lt;a href=&quot;https://github.com/hexiangnan/neural_collaborative_filtering/blob/master/GMF.py&quot;&gt;코드&lt;/a&gt;를 보면 확인할 수 있다).&lt;/p&gt;

&lt;p&gt;$a_{out}$이 identity function($y=x$)이며, $h$가 1로 이루어진 벡터라면, Matrix Factorization과 똑같아진다.&lt;/p&gt;

&lt;p&gt;실제로는 $a_{out}$과 $h$를 없애고, $p_u^G\odot p_u^M$만을 사용한다.&lt;/p&gt;

&lt;h3 id=&quot;3-neumfneural-matrix-factorization&quot;&gt;(3) NeuMF(Neural Matrix Factorization)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/80499819-67f76900-89a8-11ea-9f46-525a6837a031.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;NeuMF는 GMF와 MLP에서 얻은 최종 Layer를 Concatenate하여 결과를 낸다. GMF와 MLP를 결합해 Linearity와 Non-Linearity 모두를 얻고자 하는 모델이다.&lt;/p&gt;

&lt;p&gt;수식으로 표현하면 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/80499815-67f76900-89a8-11ea-984f-43480da9eb07.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;$p_u^G$ : User Embedding for GMF&lt;br /&gt;
$p_u^M$ : User Embedding for MLP&lt;br /&gt;
$q_i^G$ : Item Embedding for GMF&lt;br /&gt;
$q_i^M$ : Item Embedding for MLP&lt;/p&gt;

&lt;h1 id=&quot;결과&quot;&gt;결과&lt;/h1&gt;
&lt;h2 id=&quot;1-다른-모델과의-비교&quot;&gt;1. 다른 모델과의 비교&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/80499809-675ed280-89a8-11ea-8e8d-49c6c72d7ea3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-pre-training의-성과&quot;&gt;2. Pre-training의 성과&lt;/h2&gt;
&lt;p&gt;Pre-training에 대한 내용은 뒤에 나온다.&lt;br /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/80499805-662da580-89a8-11ea-97a6-29afd932fd3d.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-3가지-모델의-성능-비교&quot;&gt;3. 3가지 모델의 성능 비교&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/80499803-65950f00-89a8-11ea-925d-f29d1bca75af.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-negative-sample의-수에-따른-성능-비교&quot;&gt;4. Negative Sample의 수에 따른 성능 비교&lt;/h2&gt;
&lt;p&gt;Negative Sampling에 대한 내용은 뒤에 나온다.&lt;br /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/80499801-6463e200-89a8-11ea-9ad3-1ff6c31a7290.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;5-mlp-layer의-수에-따른-성능-비교&quot;&gt;5. MLP Layer의 수에 따른 성능 비교&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/80499792-62018800-89a8-11ea-92d8-3ed1cd21bbf9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;기타&quot;&gt;기타&lt;/h1&gt;
&lt;h2 id=&quot;1-pre-training&quot;&gt;1. Pre-training&lt;/h2&gt;
&lt;p&gt;NCF의 Loss Function은 non-convex하기 때문에 GD를 사용하면 Local Optimum에 수렴할 가능성이 있다. 이러한 경우 초기값을 어떻게 주는지가 딥러닝 모델의 성능에 큰 영향을 미친다. 저자는 미리 훈련된(pretrained) GMF, MLP 모델을 사용하여 NeuMF의 weights를 초기화하는 방식을 제안한다.&lt;/p&gt;

&lt;p&gt;방법은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;GMF와 MLP 모델을 수렴할 때 까지 훈련시킨다.&lt;/li&gt;
  &lt;li&gt;GMF와 MLP의 파라미터를 NeuMF의 해당하는 부분에 초기값으로 대입한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;2-how-to-deal-with-absence-of-negative-feedback&quot;&gt;2. How to deal with Absence of Negative Feedback&lt;/h2&gt;
&lt;p&gt;Implicit Feedback을 활용한 추천 시스템은 아마 unobserved data를 어떻게든 해결해야 할 것이다. 이 문제는 Explicit Feedback과 비교하면 명백하게 알 수 있다.&lt;/p&gt;

&lt;p&gt;점수가 1~5점 사이에 분포해 있는 Explicit Feedback의 경우 1점은 “유저가 아이템을 좋아하지 않는다”는 것을 나타내며, 5점은 “유저가 아이템을 좋아한다”는 것을 나타낸다.&lt;/p&gt;

&lt;p&gt;하지만 Implicit Feedback의 경우 0점을 기록(ex. 유저가 해당 아이템을 구매한 적이 없음)하더라도 “유저가 해당 아이템을 좋아하지 않는다”고 말할 수 없다. 유저가 실제로 아이템을 좋아하지 않는 경우 이외에도 유저가 아이템을 인지하지 못했던 경우가 있기 때문이다. 이러한 문제를 부정적인 피드백의 부재(absence of negative feedback)라고 한다.&lt;/p&gt;

&lt;p&gt;만약 부정적인 피드백를 모두 포함시켜 학습을 시킨다면 부정적인 피드백의 수가 긍정적인 피드백보다 훨씬 많아 긍정적인 피드백 무시하는 방향으로 학습이 진행될 것이다. 반대로 부정적인 피드백를 모두 제외시킨다면 긍정적인 피드백만 학습이 진행되어 우리의 최종 목표인 binary classification을 수행하지 못할 것이다.&lt;/p&gt;

&lt;p&gt;이 문제를 해결하기 위한 두 가지 방법을 제안한다. 하나는 이번 논문인 Neural Collaborative Filtering에서 사용한 방법이고, 다른 하나는 Collaborative Filtering for Implicit Feedback Datasets이라는 논문에서 사용한 방법이다.&lt;/p&gt;

&lt;h3 id=&quot;1-negative-sampling&quot;&gt;1. Negative Sampling&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Neural Collaborative Filtering&lt;/li&gt;
  &lt;li&gt;유저가 긍정적인 피드백을 준 것 이외에 유저가 아직 피드백을 주지 않은 k개의 아이템을 포함시켜 Training Set을 구성한다.(k는 하이퍼 파라미터이며, 이 논문에서는 $k=4$)&lt;/li&gt;
  &lt;li&gt;긍정적인 피드백이 $n$개라면 Training Set은 $n(k+1)$개가 된다.&lt;/li&gt;
  &lt;li&gt;즉, Negative Feedback의 일부만 샘플링해 훈련에 사용하는 방법이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-confidence-level&quot;&gt;2. Confidence Level&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Collaborative Filtering for Implicit Feedback Datasets&lt;/li&gt;
  &lt;li&gt;Confidence Level이라는 개념을 도입한다. 유저가 아이템과 연관성이 있는지 정도를 수치적으로 표현하기 위한 것이다.&lt;/li&gt;
  &lt;li&gt;$c_{ui}=1+\alpha r_{ui}$로 계산할 수 있다. $c_ui$가 클수록 유저와 아이템은 연관성이 큰 것이다.&lt;/li&gt;
  &lt;li&gt;$r_{ui}$는 긍정적인 피드백의 수이며, $r_{ui}$가 증가할수록 $c_ui$도 커진다. (증가하는 정도를 나타낸 것이 $\alpha$다. $\alpha$는 하이퍼 파라미터이며, 이 논문에서는 $\alpha=40$)&lt;/li&gt;
  &lt;li&gt;$c_{ui}$는 모두 1 이상의 값을 갖게 된다.&lt;/li&gt;
  &lt;li&gt;즉, Negative Feedback도 모두 사용해 훈련에 사용하는 방법이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-loss-function&quot;&gt;3. Loss Function&lt;/h2&gt;
&lt;p&gt;이 모델에서 output은 0과 1이므로 Bernoulli Distribution을 따른다.&lt;/p&gt;

&lt;p&gt;베르누이 분포에서 가능도는 다음과 같이 표현할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/80507963-659a0c80-89b2-11ea-9c1a-a85714fa00d1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;가능도의 negative logarithm은 다음과 같다. 이 식을 활용해서 loss를 최소화하는 방향으로 학습을 진행시킬 수 있다(식이 binary cross-entropy와 같다).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/26649034/80507967-6763d000-89b2-11ea-8d63-b4fc7d23c660.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;참고&quot;&gt;참고&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1708.05031.pdf&quot;&gt;Neural Collaborative Filtering&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;http://yifanhu.net/PUB/cf.pdf&quot;&gt;Collaborative Filtering for Implicit Feedback Datasets&lt;/a&gt;&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;employer&quot;=&gt;nil, &quot;pubmed&quot;=&gt;nil, &quot;googlescholar&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;blanik00@gmail.com&quot;, &quot;researchgate&quot;=&gt;nil, &quot;uri&quot;=&gt;nil, &quot;bitbucket&quot;=&gt;nil, &quot;codepen&quot;=&gt;nil, &quot;dribbble&quot;=&gt;nil, &quot;flickr&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;foursquare&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;google_plus&quot;=&gt;nil, &quot;keybase&quot;=&gt;nil, &quot;instagram&quot;=&gt;nil, &quot;impactstory&quot;=&gt;nil, &quot;lastfm&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;orcid&quot;=&gt;nil, &quot;pinterest&quot;=&gt;nil, &quot;soundcloud&quot;=&gt;nil, &quot;stackoverflow&quot;=&gt;nil, &quot;steam&quot;=&gt;nil, &quot;tumblr&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;vine&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;xing&quot;=&gt;nil, &quot;youtube&quot;=&gt;nil, &quot;wikipedia&quot;=&gt;nil}</name><email>blanik00@gmail.com</email></author><category term="[&quot;review&quot;]" /><summary type="html">요약 Implicit Feedback을 활용한 Collaborative Filtering을 다룬다. output이 1이면 User와 Item은 연관성이 있는 것이며, 0이면 User와 Item은 연관성이 없는 것이다. 즉, binary classification 문제이다. Collaborative Filtering에서 Matrix Factorization은 많이 쓰이는 기법이다. 기존의 Matrix Factorization은 User Latent Factor와 Item Latent Factor를 구하고, 두 Latent Factor를 내적하는 방법을 통해 Rating Matrix를 복원한다. 하지만 이 방법은 User-Item Interaction을 충분히 표현하지 못한다. 저자는 내적이라는 지나치게 단순한 방법으로 Rating Matrix를 복원했기 때문이라고 본다. 대안으로 뉴럴 네트워크의 사용을 권한다. 뉴럴 네트워크를 도입함으로써 Matrix Factorization이 가지는 Linearity와 뉴럴 네트워크가 가지는 Non-Linearity를 모두 가질 수 있다.</summary></entry><entry><title type="html">Recommender System for Ecommerce</title><link href="http://localhost:4000/project/2020/04/23/Recommender_System_for_Ecommerce" rel="alternate" type="text/html" title="Recommender System for Ecommerce" /><published>2020-04-23T00:00:00-07:00</published><updated>2020-04-23T00:00:00-07:00</updated><id>http://localhost:4000/project/2020/04/23/Recommender_System_for_Ecommerce</id><content type="html" xml:base="http://localhost:4000/project/2020/04/23/Recommender_System_for_Ecommerce">&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;식자재 마트의 온라인 쇼핑몰 추천 시스템 개발&lt;/li&gt;
  &lt;li&gt;프로젝트 시작은 2020년 03월&lt;/li&gt;
  &lt;li&gt;기존에는 MD들이 선택한 상품을 쇼핑몰에 띄우는 방식으로 추천&lt;/li&gt;
  &lt;li&gt;매출액 중 온라인 쇼핑몰이 차지하는 비중이 늘어남에 따라 추천 시스템 개발 필요해짐&lt;/li&gt;
&lt;/ul&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;employer&quot;=&gt;nil, &quot;pubmed&quot;=&gt;nil, &quot;googlescholar&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;blanik00@gmail.com&quot;, &quot;researchgate&quot;=&gt;nil, &quot;uri&quot;=&gt;nil, &quot;bitbucket&quot;=&gt;nil, &quot;codepen&quot;=&gt;nil, &quot;dribbble&quot;=&gt;nil, &quot;flickr&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;foursquare&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;google_plus&quot;=&gt;nil, &quot;keybase&quot;=&gt;nil, &quot;instagram&quot;=&gt;nil, &quot;impactstory&quot;=&gt;nil, &quot;lastfm&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;orcid&quot;=&gt;nil, &quot;pinterest&quot;=&gt;nil, &quot;soundcloud&quot;=&gt;nil, &quot;stackoverflow&quot;=&gt;nil, &quot;steam&quot;=&gt;nil, &quot;tumblr&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;vine&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;xing&quot;=&gt;nil, &quot;youtube&quot;=&gt;nil, &quot;wikipedia&quot;=&gt;nil}</name><email>blanik00@gmail.com</email></author><summary type="html">개요 식자재 마트의 온라인 쇼핑몰 추천 시스템 개발 프로젝트 시작은 2020년 03월 기존에는 MD들이 선택한 상품을 쇼핑몰에 띄우는 방식으로 추천 매출액 중 온라인 쇼핑몰이 차지하는 비중이 늘어남에 따라 추천 시스템 개발 필요해짐</summary></entry><entry><title type="html">확률 및 통계 7강</title><link href="http://localhost:4000/lecture/2020/04/16/prob_stat_07" rel="alternate" type="text/html" title="확률 및 통계 7강" /><published>2020-04-16T00:00:00-07:00</published><updated>2020-04-16T00:00:00-07:00</updated><id>http://localhost:4000/lecture/2020/04/16/%ED%99%95%EB%A5%A0%20%EB%B0%8F%20%ED%86%B5%EA%B3%84%207%EA%B0%95</id><content type="html" xml:base="http://localhost:4000/lecture/2020/04/16/prob_stat_07">&lt;h2 id=&quot;chebyshev-inequality&quot;&gt;Chebyshev Inequality&lt;/h2&gt;

&lt;p&gt;$P(|X-E[X]|\ge a)\le {\sigma_X^2 \over a^2}$&lt;/p&gt;

&lt;p&gt;어떤 랜덤한 $X$와 $X$의 평균의 차이의 정도를 $a$라 보고, $a$보다 차이가 더 많이 날 확률은 ${\sigma_X^2 \over a^2}$보다 작다.($\sigma_X^2$는 X의 분산)&lt;/p&gt;

&lt;p&gt;즉, 임의로 선택한 $X$는 $X$의 평균과 차이를 보이기 마련인데, 우리가 예측한 것(a)보다 더 크게 차이를 보일 확률은 얼마나 되는지 수치적으로 표현한 것이다.&lt;/p&gt;

&lt;h1 id=&quot;chapter-4-special-distribution&quot;&gt;Chapter 4. Special Distribution&lt;/h1&gt;
&lt;h2 id=&quot;42-bernoulli-distribution베르누이-분포&quot;&gt;4.2 Bernoulli Distribution(베르누이 분포)&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;RV X : binary&lt;/li&gt;
  &lt;li&gt;보통 하나를 success, 다른 하나를 failure라고 한다.&lt;/li&gt;
  &lt;li&gt;$P(success) = p, P(failure) = 1-p$&lt;/li&gt;
  &lt;li&gt;보통 success한 경우를 1로 두고, failure한 경우를 0으로 둔다.&lt;/li&gt;
  &lt;li&gt;$E[X]=p$&lt;/li&gt;
  &lt;li&gt;$\sigma_X^2=p(1-p)$&lt;/li&gt;
  &lt;li&gt;Bernoulli Distribution를 바탕으로 많은 Distribution이 만들어진다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;43-binomial-distribution이항분포&quot;&gt;4.3 Binomial Distribution(이항분포)&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;RV X : number of successes out of n Bernoulli trails(베르누이 시행을 n 번 반복해서 성공한 횟수)&lt;/li&gt;
  &lt;li&gt;$x=0,1,2,…,n$. 즉, discrete하다.&lt;/li&gt;
  &lt;li&gt;$P_X(x)={n \choose x}p^x(1-p)^{n-x}$&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;$\sum_{x=0}^nP_X(x)=\sum_{x=0}^n{n \choose x}p^x(1-p)^{n-x}=(p+(1-p))^n=1(\because (a+b)^n=\sum_{x=0}^n{n \choose x}a^xb^{n-x})$&lt;/li&gt;
  &lt;li&gt;$E[X]=\sum_{x=0}^nx{n \choose x}p^x(1-p)^{n-x}=np$&lt;br /&gt;
$\qquad =\sum_{x=0}^n{xn! \over (n-x)!x!}p^x(1-p)^{n-x}$&lt;br /&gt;
$\qquad =\sum_{x=0}^n{n! \over (n-x)!(x-1)!}p^x(1-p)^{n-x}$&lt;br /&gt;
$\qquad =\sum_{x=0}^n{n(n-1)! \over (n-x)!(x-1)!}p^x(1-p)^{n-x}$&lt;br /&gt;
$\qquad =\sum_{x=0}^n{n(n-1)!p \over (n-1-(x-1))!(x-1)!}p^{x-1}(1-p)^{(n-1-(x-1))}$&lt;br /&gt;
$\qquad =\sum_{x=0}^n{n(n-1)!p \over (n-1-(x-1))!(x-1)!}p^{x-1}(1-p)^{(n-1-(x-1))}$&lt;br /&gt;
$\qquad x’=x-1$로 치환&lt;br /&gt;
$\qquad =\sum_{x=0}^{n-1}np{(n-1)!px’(1-p)^{n-1-x’} \over (n-1-x’)!(x’)!}$&lt;br /&gt;
$\qquad =np(p+(1-p))^{n-1}$&lt;br /&gt;
$\qquad =np$&lt;/li&gt;
  &lt;li&gt;$\sigma_X^2[X]=E[X^2]-(E[X])^2$&lt;br /&gt;
$E[X^2]=\sum_{x=0}^n{x^2n!\over (n-x)!x!}p^x(1-p)^{n-x}$&lt;br /&gt;
$\qquad =\sum_{x=1}^n{xn!\over (n-x)!(x-1)!}p^x(1-p)^{n-x}$&lt;br /&gt;
$\qquad =\sum_{x=1}^n{(x-1)n!\over (n-x)!(x-1)!}p^x(1-p)^{n-x}+\sum_{x=1}^n{n!\over (n-x)!(x-1)!}p^x(1-p)^{n-x}$&lt;br /&gt;
$\qquad =\sum_{x=1}^n{(x-1)n!\over (n-x)!(x-1)!}p^x(1-p)^{n-x}+np$&lt;br /&gt;
$\qquad =\sum_{x=2}^n{n!\over (n-x)!(x-2)!}p^x(1-p)^{n-x}+np$&lt;br /&gt;
$\qquad =\sum_{x=2}^n{n(n-1)(n-2)!\over ((n-2)-(x-2))!(x-2)!}p^2p^{x-2}(1-p)^{(n-x)-(x-2)}+np$&lt;br /&gt;
$\qquad x’=x-2$로 치환&lt;br /&gt;
$\qquad =\sum_{x=2}^n{n-2 \choose x’}p^{x’}(1-p)^{n-2-x’}n(n-1)p^2+np$&lt;br /&gt;
$\qquad =(p+(1-p))^{n-2}n(n-1)p^2+np$&lt;br /&gt;
$\qquad \therefore \sigma_X^2=E[X^2]-n^2p^2$&lt;br /&gt;
$\qquad =np(1-p)$&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;44-geometrid-distribution기하분포&quot;&gt;4.4 Geometrid Distribution(기하분포)&lt;/h2&gt;
&lt;p&gt;RV X : Number of Bernoulli trials until first success&lt;br /&gt;
$P_X(x)=(1-p)^{x-1}p$, $x=1,2,3,…$&lt;br /&gt;
$E[X]={1\over p}$&lt;br /&gt;
$\sigma_X^2={1-p\over p^2}$&lt;/p&gt;

&lt;h3 id=&quot;forgetfulnessmemoryless&quot;&gt;Forgetfulness(Memoryless)&lt;/h3&gt;
&lt;p&gt;6이 나올 때 까지 주사위를 던지는 확률 변수라고 하자.&lt;br /&gt;
10번을 던졌는데 6이 안나왔다. 이 경우에 다섯 번을 더 던져 6이 나올 확률은 얼마일까? 이것은 기하분포 공식을 통해 계산해낼 수 있다. $(1-p)^4p$이다.&lt;br /&gt;
이번에는 15번을 던졌는데 6이 안나왔다. 이 경우에도 다섯 번을 더 던져 6이 나올 확률은 얼마인지 계산해보자. $(1-p)^4p$이다.&lt;br /&gt;
이 예시는 기하 분포가 과거 기록에 영향을 받지 않는다는 것을 보여준다. 이런 성질을 Forgetfulness라고 한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Consider K additional trials until the first success, given n trials fail.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;$P(X=n+k|X&amp;gt;n)$&lt;br /&gt;
$={P(X=n+k\cap X&amp;gt;n)\over P(X&amp;gt;n)}$&lt;br /&gt;
$={P(X=n+k)\over P(X&amp;gt;n)}$&lt;br /&gt;
$={(1-p)^{n+k-1}p\over \sum_{x=n+1}^{\infty}(1-p)^{x-1}p}$&lt;br /&gt;
$={(1-p)^{n+k-1}p\over {p(1-p)^n\over 1-(1-p)}}$&lt;br /&gt;
$=p(1-p)^{k-1}$&lt;br /&gt;
$=P(X=k)$&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;employer&quot;=&gt;nil, &quot;pubmed&quot;=&gt;nil, &quot;googlescholar&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;blanik00@gmail.com&quot;, &quot;researchgate&quot;=&gt;nil, &quot;uri&quot;=&gt;nil, &quot;bitbucket&quot;=&gt;nil, &quot;codepen&quot;=&gt;nil, &quot;dribbble&quot;=&gt;nil, &quot;flickr&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;foursquare&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;google_plus&quot;=&gt;nil, &quot;keybase&quot;=&gt;nil, &quot;instagram&quot;=&gt;nil, &quot;impactstory&quot;=&gt;nil, &quot;lastfm&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;orcid&quot;=&gt;nil, &quot;pinterest&quot;=&gt;nil, &quot;soundcloud&quot;=&gt;nil, &quot;stackoverflow&quot;=&gt;nil, &quot;steam&quot;=&gt;nil, &quot;tumblr&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;vine&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;xing&quot;=&gt;nil, &quot;youtube&quot;=&gt;nil, &quot;wikipedia&quot;=&gt;nil}</name><email>blanik00@gmail.com</email></author><category term="[&quot;lecture&quot;]" /><category term="확률 및 통계" /><summary type="html">Chebyshev Inequality</summary></entry><entry><title type="html">Collaborative Filtering for Implicit Feedback Datasets</title><link href="http://localhost:4000/paper_review/2020/04/16/Collaborative_Filtering_for_Implicit_Feedback_Datasets" rel="alternate" type="text/html" title="Collaborative Filtering for Implicit Feedback Datasets" /><published>2020-04-16T00:00:00-07:00</published><updated>2020-04-16T00:00:00-07:00</updated><id>http://localhost:4000/paper_review/2020/04/16/Collaborative_Filtering_for_Implicit_Feedback_Datasets</id><content type="html" xml:base="http://localhost:4000/paper_review/2020/04/16/Collaborative_Filtering_for_Implicit_Feedback_Datasets"></content><author><name>{&quot;name&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;employer&quot;=&gt;nil, &quot;pubmed&quot;=&gt;nil, &quot;googlescholar&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;blanik00@gmail.com&quot;, &quot;researchgate&quot;=&gt;nil, &quot;uri&quot;=&gt;nil, &quot;bitbucket&quot;=&gt;nil, &quot;codepen&quot;=&gt;nil, &quot;dribbble&quot;=&gt;nil, &quot;flickr&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;foursquare&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;google_plus&quot;=&gt;nil, &quot;keybase&quot;=&gt;nil, &quot;instagram&quot;=&gt;nil, &quot;impactstory&quot;=&gt;nil, &quot;lastfm&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;orcid&quot;=&gt;nil, &quot;pinterest&quot;=&gt;nil, &quot;soundcloud&quot;=&gt;nil, &quot;stackoverflow&quot;=&gt;nil, &quot;steam&quot;=&gt;nil, &quot;tumblr&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;vine&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;xing&quot;=&gt;nil, &quot;youtube&quot;=&gt;nil, &quot;wikipedia&quot;=&gt;nil}</name><email>blanik00@gmail.com</email></author><category term="[&quot;review&quot;]" /><summary type="html"></summary></entry><entry><title type="html">확률 및 통계 6강</title><link href="http://localhost:4000/lecture/2020/04/14/prob_stat_06" rel="alternate" type="text/html" title="확률 및 통계 6강" /><published>2020-04-14T00:00:00-07:00</published><updated>2020-04-14T00:00:00-07:00</updated><id>http://localhost:4000/lecture/2020/04/14/%ED%99%95%EB%A5%A0%20%EB%B0%8F%20%ED%86%B5%EA%B3%84%206%EA%B0%95</id><content type="html" xml:base="http://localhost:4000/lecture/2020/04/14/prob_stat_06">&lt;h2 id=&quot;예시---geometric-distribution기하분포&quot;&gt;예시 - Geometric Distribution(기하분포)&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;RV K: Number of trials until first success&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;예시---tossing-a-dice-until-first-6&quot;&gt;예시 - Tossing a dice until first 6&lt;/h3&gt;
&lt;p&gt;p: 6이 나올 확률&lt;br /&gt;
(1-p): 6 이외의 수가 나올 확률&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;첫 번째 시도에서 성공&lt;br /&gt;
$k=1, p$&lt;/li&gt;
  &lt;li&gt;두 번째 시도에서 성공&lt;br /&gt;
$k=2, (1-p)p$&lt;/li&gt;
  &lt;li&gt;세 번째 시도에서 성공&lt;br /&gt;
$k=3, (1-p)(1-p)p$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;즉, $P_K(k)=(1-p)^{k-1}p\quad(k=1,2,3,4,…)$&lt;/p&gt;

&lt;h3 id=&quot;mean&quot;&gt;Mean&lt;/h3&gt;
&lt;p&gt;$E[K]=\sum_{k=1}^{\infty}kp(1-p)^{k-1}$&lt;br /&gt;
$\sum_{k=1}^{\infty}(1-p)^{k}={1-p \over p}$&lt;br /&gt;
${d \over dp}\sum_{k=1}^{\infty}(1-p)^{k}={d \over dp}({1-p \over p})$&lt;br /&gt;
$=-\sum_{k=1}^{\infty}k(1-p)^{k-1}=-{1 \over p^2}$&lt;br /&gt;
$=\sum_{k=1}^{\infty}k(1-p)^{k-1}={1 \over p^2}$&lt;br /&gt;
$\therefore E[K]=p{1 \over p^2}={1 \over p}$&lt;/p&gt;

&lt;h3 id=&quot;variance&quot;&gt;Variance&lt;/h3&gt;
&lt;p&gt;$\sigma_k^2=E[K^2]-\mu^2$&lt;br /&gt;
$E[K^2]=\sum_{k=1}^{\infty}k^2p(1-p)^{k-1}$&lt;br /&gt;
$\Rightarrow -{d \over dp}\sum_{k=1}^{\infty}k(1-p)^{k-1}=-{d \over dp}{1 \over p^2}$(Mean 구하는 공식에서 가져옴)&lt;br /&gt;
$\qquad=-\sum_{k=1}^{\infty}k(k-1)(1-p)^{k-2}=-{2\over p^3}$&lt;br /&gt;
$\qquad=\sum_{k=1}^{\infty}k(k-1)(1-p)^{k-2}={2\over p^3}$&lt;br /&gt;
$\Rightarrow \sum_{k=1}^{\infty}k^2(1-p)^{k-2}=\sum_{k=1}^{\infty}k(1-p)^{k-2}+{2\over p^3}$&lt;br /&gt;
$\qquad =\sum_{k=1}^{\infty}k^2(1-p)^{k-2}p(1-p)=(\sum_{k=1}^{\infty}k(1-p)^{k-2}+{2\over p^3})p(1-p)$&lt;br /&gt;
$\qquad =\sum_{k=1}^{\infty}k(1-p)^{k-1}p+{2(1-p)\over p^2}$&lt;br /&gt;
$\qquad ={1\over p}+{2(1-p)\over p^2}$&lt;br /&gt;
$\therefore \sigma_k^2=E[K^2]-\mu^2={1\over p}+{2(1-p)\over p^2}-{1\over p^2}={1-p \over p^2}$&lt;/p&gt;

&lt;h2 id=&quot;conditional-mean&quot;&gt;Conditional Mean&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;$E[X|A]=\sum_{x_i\in A}x_ip(x_i|A)$&lt;/li&gt;
  &lt;li&gt;A의 조건을 만족하는 변수값들에 대해서만 평균값을 구한 것&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;이산확률변수의 경우&lt;/strong&gt;&lt;br /&gt;
$\sum_{x_i\in A}x_i{p(x_i \cap A) \over p(A)}$&lt;br /&gt;
$\qquad =\sum_{x_i\in A}x_i{p(x_i) \over p(A)}$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;연속확률변수의 경우&lt;/strong&gt;&lt;br /&gt;
$E[X|A]=\int_{x\in A}xf_X(x|A)$
연속형이기 때문에 density를 구해줘야 하는데, 이 경우에는 conditional density($f_X(x|A)$)를 구해야 한다.&lt;br /&gt;
이것을 바로 구할 수는 없고, conditional CDF를 활용해 구한다.&lt;br /&gt;
$f_X(x|A)={d \over dx}F_X(x|A)$&lt;br /&gt;
$\qquad\qquad ={d \over dx}P(X\le x|A)$&lt;br /&gt;
$\qquad\qquad ={d \over dx}{P(X\le x\cap A)\over P(A)}$&lt;/p&gt;</content><author><name>{&quot;name&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;location&quot;=&gt;nil, &quot;employer&quot;=&gt;nil, &quot;pubmed&quot;=&gt;nil, &quot;googlescholar&quot;=&gt;nil, &quot;email&quot;=&gt;&quot;blanik00@gmail.com&quot;, &quot;researchgate&quot;=&gt;nil, &quot;uri&quot;=&gt;nil, &quot;bitbucket&quot;=&gt;nil, &quot;codepen&quot;=&gt;nil, &quot;dribbble&quot;=&gt;nil, &quot;flickr&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;foursquare&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;google_plus&quot;=&gt;nil, &quot;keybase&quot;=&gt;nil, &quot;instagram&quot;=&gt;nil, &quot;impactstory&quot;=&gt;nil, &quot;lastfm&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;orcid&quot;=&gt;nil, &quot;pinterest&quot;=&gt;nil, &quot;soundcloud&quot;=&gt;nil, &quot;stackoverflow&quot;=&gt;nil, &quot;steam&quot;=&gt;nil, &quot;tumblr&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;vine&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;xing&quot;=&gt;nil, &quot;youtube&quot;=&gt;nil, &quot;wikipedia&quot;=&gt;nil}</name><email>blanik00@gmail.com</email></author><category term="[&quot;lecture&quot;]" /><category term="확률 및 통계" /><summary type="html">예시 - Geometric Distribution(기하분포) RV K: Number of trials until first success</summary></entry></feed>