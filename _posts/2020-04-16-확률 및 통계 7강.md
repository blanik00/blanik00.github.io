---
title: '확률 및 통계 7강'
date: 2020-04-16
permalink: /lecture/2020/04/16/prob_stat_07
category:
  - lecture
tags:
  - 확률 및 통계
---

## Chebyshev Inequality

$P(\|X-E[X]\|\ge a)\le {\sigma_X^2 \over a^2}$  

어떤 랜덤한 $X$와 $X$의 평균의 차이의 정도를 $a$라 보고, $a$보다 차이가 더 많이 날 확률은 ${\sigma_X^2 \over a^2}$보다 작다.($\sigma_X^2$는 X의 분산)  

즉, 임의로 선택한 $X$는 $X$의 평균과 차이를 보이기 마련인데, 우리가 예측한 것(a)보다 더 크게 차이를 보일 확률은 얼마나 되는지 수치적으로 표현한 것이다.  

# Chapter 4. Special Distribution
## 4.2 Bernoulli Distribution(베르누이 분포)
- RV X : binary  
- 보통 하나를 success, 다른 하나를 failure라고 한다.  
- $P(success) = p, P(failure) = 1-p$  
- 보통 success한 경우를 1로 두고, failure한 경우를 0으로 둔다.  
- $E[X]=p$  
- $\sigma_X^2=p(1-p)$  
- Bernoulli Distribution를 바탕으로 많은 Distribution이 만들어진다.

## 4.3 Binomial Distribution(이항분포)  
- RV X : number of successes out of n Bernoulli trails(베르누이 시행을 n 번 반복해서 성공한 횟수)  
- $x=0,1,2,...,n$. 즉, discrete하다.  
- $P_X(x)={n \choose x}p^x(1-p)^{n-x}$  

1. $\sum_{x=0}^nP_X(x)=\sum_{x=0}^n{n \choose x}p^x(1-p)^{n-x}=(p+(1-p))^n=1(\because (a+b)^n=\sum_{x=0}^n{n \choose x}a^xb^{n-x})$
2. $E[X]=\sum_{x=0}^nx{n \choose x}p^x(1-p)^{n-x}=np$  
$\qquad =\sum_{x=0}^n{xn! \over (n-x)!x!}p^x(1-p)^{n-x}$  
$\qquad =\sum_{x=0}^n{n! \over (n-x)!(x-1)!}p^x(1-p)^{n-x}$  
$\qquad =\sum_{x=0}^n{n(n-1)! \over (n-x)!(x-1)!}p^x(1-p)^{n-x}$  
$\qquad =\sum_{x=0}^n{n(n-1)!p \over (n-1-(x-1))!(x-1)!}p^{x-1}(1-p)^{(n-1-(x-1))}$  
$\qquad =\sum_{x=0}^n{n(n-1)!p \over (n-1-(x-1))!(x-1)!}p^{x-1}(1-p)^{(n-1-(x-1))}$  
$\qquad x'=x-1$로 치환  
$\qquad =\sum_{x=0}^{n-1}np{(n-1)!px'(1-p)^{n-1-x'} \over (n-1-x')!(x')!}$  
$\qquad =np(p+(1-p))^{n-1}$  
$\qquad =np$  
3. $\sigma_X^2[X]=E[X^2]-(E[X])^2$  
$E[X^2]=\sum_{x=0}^n{x^2n!\over (n-x)!x!}p^x(1-p)^{n-x}$  
$\qquad =\sum_{x=1}^n{xn!\over (n-x)!(x-1)!}p^x(1-p)^{n-x}$  
$\qquad =\sum_{x=1}^n{(x-1)n!\over (n-x)!(x-1)!}p^x(1-p)^{n-x}+\sum_{x=1}^n{n!\over (n-x)!(x-1)!}p^x(1-p)^{n-x}$  
$\qquad =\sum_{x=1}^n{(x-1)n!\over (n-x)!(x-1)!}p^x(1-p)^{n-x}+np$  
$\qquad =\sum_{x=2}^n{n!\over (n-x)!(x-2)!}p^x(1-p)^{n-x}+np$  
$\qquad =\sum_{x=2}^n{n(n-1)(n-2)!\over ((n-2)-(x-2))!(x-2)!}p^2p^{x-2}(1-p)^{(n-x)-(x-2)}+np$  
$\qquad x'=x-2$로 치환  
$\qquad =\sum_{x=2}^n{n-2 \choose x'}p^{x'}(1-p)^{n-2-x'}n(n-1)p^2+np$  
$\qquad =(p+(1-p))^{n-2}n(n-1)p^2+np$  
$\qquad \therefore \sigma_X^2=E[X^2]-n^2p^2$  
$\qquad =np(1-p)$  

## 4.4 Geometrid Distribution(기하분포)
RV X : Number of Bernoulli trials until first success  
$P_X(x)=(1-p)^{x-1}p$, $x=1,2,3,...$  
$E[X]={1\over p}$  
$\sigma_X^2={1-p\over p^2}$  

### Forgetfulness(Memoryless)  
6이 나올 때 까지 주사위를 던지는 확률 변수라고 하자.  
10번을 던졌는데 6이 안나왔다. 이 경우에 다섯 번을 더 던져 6이 나올 확률은 얼마일까? 이것은 기하분포 공식을 통해 계산해낼 수 있다. $(1-p)^4p$이다.  
이번에는 15번을 던졌는데 6이 안나왔다. 이 경우에도 다섯 번을 더 던져 6이 나올 확률은 얼마인지 계산해보자. $(1-p)^4p$이다.  
이 예시는 기하 분포가 과거 기록에 영향을 받지 않는다는 것을 보여준다. 이런 성질을 Forgetfulness라고 한다.  

> Consider K additional trials until the first success, given n trials fail.  

$P(X=n+k\|X>n)$  
$={P(X=n+k\cap X>n)\over P(X>n)}$  
$={P(X=n+k)\over P(X>n)}$  
$={(1-p)^{n+k-1}p\over \sum_{x=n+1}^{\infty}(1-p)^{x-1}p}$  
$={(1-p)^{n+k-1}p\over {p(1-p)^n\over 1-(1-p)}}$  
$=p(1-p)^{k-1}$  
$=P(X=k)$  




























